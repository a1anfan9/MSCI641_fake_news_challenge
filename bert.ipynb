{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from score import report_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"fnc-1\"\n",
    "manual_seed=47\n",
    "num_train_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_bodies = pd.read_csv(datadir + '/train_bodies.csv')   \n",
    "raw_train_stances = pd.read_csv(datadir + '/train_stances.csv')\n",
    "raw_test_bodies = pd.read_csv(datadir + '/competition_test_bodies.csv') \n",
    "raw_test_stances = pd.read_csv(datadir + '/competition_test_stances.csv')\n",
    "\n",
    "true_test = raw_test_stances['Stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_to_int = {\"agree\":0, \"discuss\": 1, \"disagree\": 2, \"unrelated\": 3}\n",
    "int_to_stance = {0:\"agree\", 1:\"discuss\", 2:\"disagree\", 3: \"unrelated\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_stances = raw_test_stances['Stance']\n",
    "raw_train_stances['Stance'] = raw_train_stances['Stance'].apply(lambda x: stance_to_int[x])\n",
    "raw_test_stances['Stance'] = raw_test_stances['Stance'].apply(lambda x: stance_to_int[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = raw_train_stances.join(raw_train_bodies.set_index('Body ID'), on='Body ID')\n",
    "test_df = raw_test_stances.join(raw_test_bodies.set_index('Body ID'), on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = train_df['Stance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Body ID','Stance'], axis=1)\n",
    "test_df = test_df.drop(['Body ID','Stance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
    "\n",
    "train_df['Headline'] = train_df['Headline'].apply(clean)\n",
    "train_df['articleBody'] = train_df['articleBody'].apply(clean)\n",
    "\n",
    "test_df['Headline'] = test_df['Headline'].apply(clean)\n",
    "test_df['articleBody'] = test_df['articleBody'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.rename(columns={'Headline': 'text_a', 'articleBody': 'text_b'})\n",
    "test_df=test_df.rename(columns={'Headline': 'text_a', 'articleBody': 'text_b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl=[]\n",
    "for i in range(len(test_df)):\n",
    "  test_dl.append([test_df['text_a'][i], test_df['text_b'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(\n",
    "    'bert', 'bert-base-cased', \n",
    "    num_labels=4, \n",
    "    args={\n",
    "        'num_train_epochs': num_train_epochs,\n",
    "        'manual_seed': manual_seed,\n",
    "        'max_seq_length': 256,\n",
    "        'output_dir': \"outputs/bert\",\n",
    "        'overwrite_output_dir': True,\n",
    "        'save_steps': -1,\n",
    "        'early_stopping': True},\n",
    "    use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train_model(train_df)\n",
    "model = ClassificationModel(\"bert\", \"outputs/bert/checkpoint-18741-epoch-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21b92b8349a4e6990e67f4b25c404f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91be33a0bf44609590705fbac3e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds , _ = model.predict(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [int_to_stance[int(p)] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |   1351    |    113    |    356    |    83     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    231    |    268    |    119    |    79     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    807    |    208    |   3250    |    199    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    34     |    10     |    118    |   18187   |\n",
      "-------------------------------------------------------------\n",
      "Score: 9874.25 out of 11651.25\t(84.74841755176483%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.74841755176483"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_score(true_test, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatedness Accuracy is 0.979419981899028\n",
      "Opinion Accuracy is 0.6892695356738392\n"
     ]
    }
   ],
   "source": [
    "# Find Relatedness Accuracy and Opinion Accuracy\n",
    "# stance_to_int = {\"agree\":0, \"discuss\": 1, \"disagree\": 2, \"unrelated\": 3}\n",
    "true_test_labels = true_test.apply(lambda x: stance_to_int[x])\n",
    "\n",
    "relatedness_correct = 0\n",
    "opinion_correct = 0\n",
    "opinion_count = 0\n",
    "\n",
    "for i in range(len(true_test_labels)):\n",
    "    label = true_test_labels[i]\n",
    "    pred = preds[i]\n",
    "    if (label == 3 and pred == 3) or (label != 3 and pred != 3):\n",
    "        relatedness_correct+=1\n",
    "    if label != 3:\n",
    "        opinion_count+=1\n",
    "        if label == pred:\n",
    "            opinion_correct += 1\n",
    "\n",
    "\n",
    "print(f\"Relatedness Accuracy is {relatedness_correct/len(true_test_labels)}\")\n",
    "print(f\"Opinion Accuracy is {opinion_correct/opinion_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e8c2f1beb2e40a9a38baaa548f28e428769bf26bad7d7d25cc139235a548e0b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
